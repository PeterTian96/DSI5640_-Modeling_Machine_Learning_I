library('randomForest')  ## fit random forest
library('dplyr')    ## data manipulation
library('magrittr') ## for '%<>%' operator
library(caret)
library('viridis')  ## viridis color palette
library('gpairs')   ## pairs plot
install.packages('gpairs')
install.packages('lmtest')
library('randomForest')  ## fit random forest
library('dplyr')    ## data manipulation
library('magrittr') ## for '%<>%' operator
library(caret)
library('viridis')  ## viridis color palette
library('gpairs')   ## pairs plot
library('randomForest')  ## fit random forest
library('dplyr')    ## data manipulation
library('magrittr') ## for '%<>%' operator
library(caret)
library('viridis')  ## viridis color palette
library('gpairs')   ## pairs plot
install.packages('gpairs')
install.packages('lmtest')
library('randomForest')  ## fit random forest
library('dplyr')    ## data manipulation
library('magrittr') ## for '%<>%' operator
library(lmtest)
install.packages('gpairs')
install.packages('lmtest')
install.packages('lmtest')
tunegrid <- expand.grid(.mtry = samp_vars,
.min.node.size = node_size,
.splitrule = "gini")
tunegrid <- expand.grid(.mtry = samle_variables,
.min.node.size = node,
.splitrule = "gini")
samle_variables <- c(3,4,5)
node <-c(1, 5, 10, 20, 40, 80)
setcontrol <- trainControl(method='cv',
number=5,
search="grid")
set.seed(1)
tunegrid <- expand.grid(.mtry = samle_variables,
.min.node.size = node,
.splitrule = "gini")
tunegrid <- expand.grid(.mtry = samle_variables,
.min.node.size = node,
.splitrule = "gini")
randomforest_fit <- train(y~.,
data = train_data,
trControl = control,
metric = "Accuracy",
method = 'ranger',
tuneGrid = tunegrid,
classification = TRUE)
train_data <- read.csv("vowel.train.txt")
train_data$y <- as.factor(train_data$y)
train_data <- train_data[2:11]
train_data
vowel_fit <- randomForest(y ~ ., data=train_data)
vowel_fit
samle_variables <- c(3,4,5)
node <-c(1, 5, 10, 20, 40, 80)
setcontrol <- trainControl(method='cv',
number=5,
search="grid")
set.seed(1)
tunegrid <- expand.grid(.mtry = samle_variables,
.min.node.size = node,
.splitrule = "gini")
randomforest_fit <- train(y~.,
data = train_data,
trControl = control,
metric = "Accuracy",
method = 'ranger',
tuneGrid = tunegrid,
classification = TRUE)
tunegrid <- expand.grid(.mtry = samle_variables,
.min.node.size = node,
.splitrule = "gini")
randomforest_fit <- train(y~.,
data = train_data,
trControl = setcontrol,
metric = "Accuracy",
method = 'ranger',
tuneGrid = tunegrid,
classification = TRUE)
tune_params <- as.data.frame(randomforest_fit[4])
tune <- as.data.frame(randomforest_fit[4])
tune <- tune_params %>% arrange(desc(results.Accuracy)) # sort by accuracy and select the params with best accuracy
tune[1,]
set.seed(2)
rf_best_fit <- randomForest(y ~ .,
data=train,
nodesize=1,
mtry=3)
set.seed(2)
rf_best_fit <- randomForest(y ~ .,
data=setcontrol,
nodesize=1,
mtry=3)
set.seed(2)
best_fit <- randomForest(y ~ .,
data=train_data,
nodesize=1,
mtry=3)
set.seed(2)
best_fit <- randomForest(y ~ .,
data=train_data,
nodesize=1,
mtry=3)
best_fit
test_data <- read_csv("vowel.test.txt")
test_data <- read_csv("vowel.test.txt")
train_data <- read.csv("vowel.train.txt")
train_data$y <- as.factor(train_data$y)
train_data <- train_data[2:11]
train_data
install.packages('lmtest')
library('randomForest')  ## fit random forest
library('dplyr')    ## data manipulation
library('magrittr') ## for '%<>%' operator
library(lmtest)
library('randomForest')  ## fit random forest
library('dplyr')    ## data manipulation
library('magrittr') ## for '%<>%' operator
library(caret)
library('viridis')  ## viridis color palette
library('gpairs')   ## pairs plot
library('randomForest')  ## fit random forest
library('dplyr')    ## data manipulation
library('magrittr') ## for '%<>%' operator
library(caret)
library('viridis')  ## viridis color palette
train_data <- read.csv("vowel.train.txt")
train_data$y <- as.factor(train_data$y)
train_data <- train_data[2:11]
train_data
vowel_fit <- randomForest(y ~ ., data=train_data)
vowel_fit
samle_variables <- c(3,4,5)
node <-c(1, 5, 10, 20, 40, 80)
setcontrol <- trainControl(method='cv',
number=5,
search="grid")
set.seed(1)
tunegrid <- expand.grid(.mtry = samle_variables,
.min.node.size = node,
.splitrule = "gini")
randomforest_fit <- train(y~.,
data = train_data,
trControl = setcontrol,
metric = "Accuracy",
method = 'ranger',
tuneGrid = tunegrid,
classification = TRUE)
tune <- as.data.frame(randomforest_fit[4])
tune <- tune_params %>% arrange(desc(results.Accuracy)) # sort by accuracy and select the params with best accuracy
tune[1,]
set.seed(2)
best_fit <- randomForest(y ~ .,
data=train_data,
nodesize=1,
mtry=3)
best_fit
test_data <- read_csv("vowel.test.txt")
test_data <- read.csv("vowel.test.txt")
test_data$y <- as.factor(test_data$y)
test_data <- test_data[2:11]
test_data <- read.csv("vowel.test.txt")
test_data$y <- as.factor(test_data$y)
test_data <- test_data[2:11]
test_data
#from the test data model we could know that when the mtry=3 and nodesize=1, error is minimal
test_fit <- randomForest(y ~ ., data=vowel.train,mtry=3,nodesize=1)
#from the test data model we could know that when the mtry=3 and nodesize=1, error is minimal
test_fit <- randomForest(y ~ ., data=test_data,mtry=3,nodesize=1)
test_pred <- predict(test_fit, test_data)
err.test <- 1 - mean(test_fit ==test_fit$y )
err.test
library('randomForest')  ## fit random forest
library('dplyr')    ## data manipulation
library('magrittr') ## for '%<>%' operator
library(caret)
library('viridis')  ## viridis color palette
train_data <- read.csv("vowel.train.txt")
train_data$y <- as.factor(train_data$y)
train_data <- train_data[2:11]
train_data
vowel_fit <- randomForest(y ~ ., data=train_data)
vowel_fit
sample_variables <- c(3,4,5)
node <-c(1, 5, 10, 20, 40, 80)
setcontrol <- trainControl(method='cv',
number=5,
search="grid")
set.seed(1)
tunegrid <- expand.grid(.mtry = sample_variables,
.min.node.size = node,
.splitrule = "gini")
randomforest_fit <- train(y~.,
data = train_data,
trControl = setcontrol,
metric = "Accuracy",
method = 'ranger',
tuneGrid = tunegrid,
classification = TRUE)
tune <- as.data.frame(randomforest_fit[4])
tune <- tune_params %>% arrange(desc(results.Accuracy)) # sort by accuracy and select the params with best accuracy
tune[1,]
set.seed(2)
best_fit <- randomForest(y ~ ., data=train_data,mtry=3,nodesize=1)
best_fit
test_data <- read.csv("vowel.test.txt")
test_data$y <- as.factor(test_data$y)
test_data <- test_data[2:11]
test_data
#from the test data model we could know that when the mtry=3 and nodesize=1, error is minimal
test_fit <- randomForest(y ~ ., data=test_data,mtry=3,nodesize=1)
test_pred <- predict(test_fit, test_data)
err.test <- 1 - mean(test_fit ==test_fit$y )
err.test
library('randomForest')  ## fit random forest
library('dplyr')    ## data manipulation
library('magrittr') ## for '%<>%' operator
library(caret)
install.packages('caret')
library('randomForest')  ## fit random forest
library('dplyr')    ## data manipulation
library('magrittr') ## for '%<>%' operator
library(caret)
library('viridis')  ## viridis color palette
library('randomForest')  ## fit random forest
library('dplyr')    ## data manipulation
library('magrittr') ## for '%<>%' operator
library(caret)
library('viridis')  ## viridis color palette
train_data <- read.csv("vowel.train.txt")
train_data$y <- as.factor(train_data$y)
train_data <- train_data[2:11]
train_data
vowel_fit <- randomForest(y ~ ., data=train_data)
vowel_fit
sample_variables <- c(3,4,5)
node <-c(1, 5, 10, 20, 40, 80)
setcontrol <- trainControl(method='cv',
number=5,
search="grid")
set.seed(1)
tunegrid <- expand.grid(.mtry = sample_variables,
.min.node.size = node,
.splitrule = "gini")
randomforest_fit <- train(y~.,
data = train_data,
trControl = setcontrol,
metric = "Accuracy",
method = 'ranger',
tuneGrid = tunegrid,
classification = TRUE)
tune <- as.data.frame(randomforest_fit[4])
tune <- tune %>% arrange(desc(results.Accuracy)) # sort by accuracy and select the params with best accuracy
tune[1,]
set.seed(2)
best_fit <- randomForest(y ~ ., data=train_data,mtry=3,nodesize=1)
best_fit
test_data <- read.csv("vowel.test.txt")
test_data$y <- as.factor(test_data$y)
test_data <- test_data[2:11]
test_data
#from the test data model we could know that when the mtry=3 and nodesize=1, error is minimal
test_fit <- randomForest(y ~ ., data=test_data,mtry=3,nodesize=1)
test_pred <- predict(test_fit, test_data)
err.test <- 1 - mean(test_fit ==test_fit$y )
err.test
#from the test data model we could know that when the mtry=3 and nodesize=1, error is minimal
test_pred <- predict(best_fit, test_data)
err.test <- 1 - mean(best_fit ==test_fit$y )
err.test
